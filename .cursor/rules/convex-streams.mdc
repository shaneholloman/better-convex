---
description: Advanced query patterns using Convex streams for unions, joins, filtering, and pagination with consistent page sizes
globs: **/*.ts,**/*.tsx
alwaysApply: false
---

# Convex Streams

This document covers advanced query patterns using Convex streams. Streams solve complex querying needs including unions, joins, filtering with pagination, and SQL-like patterns.

**IMPORTANT:** Streams have not yet been migrated to Convex Ents and still require `ctx.db` in the first parameter only: `stream(ctx.db, schema)`. However, inside stream operations (like `filterWith`, `map`, etc.), you CAN and SHOULD use `ctx.table()` for database operations.

## Overview

Streams are async iterables of documents that enable advanced query patterns beyond basic Convex queries. They're essential for:

- **Consistent pagination with filters** - Get exactly N items per page
- **UNION operations** - Merge multiple queries
- **Complex JOINs** - Paginate through joined data
- **DISTINCT values** - Get unique results efficiently
- **Index skip scans** - Query patterns with partial index matches

## Getting Started

**Edit:** `convex/*.ts` files

### Basic Stream Syntax

```typescript
import { stream } from 'convex-helpers/server/stream';
import schema from './schema';

// NOTE: Stream initialization requires ctx.db (not yet migrated to Ents)
const messages = stream(ctx.db, schema)
  .query('messages')
  .withIndex('userId', (q) => q.eq('userId', userId))
  .order('desc');

// Use like regular queries
const first = await messages.first();
const page = await messages.paginate(paginationOpts);
const all = await messages.collect(); // Use sparingly
```

**IMPORTANT LIMITATION:** Streams do NOT support `withSearchIndex()`. You cannot combine streams with full-text search. If you need both complex filtering and search, see [convex-search.mdc](mdc:.cursor/rules/convex-search.mdc) for alternative approaches.

## Core Stream Patterns

### 1. FilterWith - Consistent Page Sizes

**Problem:** The filter helper causes variable page sizes with pagination (built-in `.filter()` does NOT have this problem, but is limited to simple comparisons).

**Solution:** Use `filterWith` to filter BEFORE pagination.

```typescript
export const searchCharacters = createPublicPaginatedQuery()({
  args: {
    category: z.string().optional(),
    minScore: z.number().optional(),
  },
  handler: async (ctx, args) => {
    // Filter BEFORE pagination for consistent page sizes
    // NOTE: Stream initialization requires ctx.db
    return await stream(ctx.db, schema)
      .query('characters')
      .withIndex('private', (q) => q.eq('private', false))
      .filterWith(async (char) => {
        // Complex filtering with full TypeScript
        if (args.category && !char.categories?.includes(args.category)) {
          return false;
        }
        if (args.minScore && char.score < args.minScore) {
          return false;
        }
        // Can do async lookups - use ctx.table() inside streams!
        const author = await ctx.table('user').get(char.userId);
        return author && !author.isBanned;
      })
      .paginate(args.paginationOpts); // Consistent page sizes!
  },
});
```

### 2. Merge Streams (UNION)

Combine multiple queries into a single stream:

```typescript
import { mergedStream } from 'convex-helpers/server/stream';

export const conversation = createPublicPaginatedQuery()({
  args: {
    u1: zid('user'),
    u2: zid('user'),
  },
  handler: async (ctx, args) => {
    // Stream of messages u1 → u2
    const messages1 = stream(ctx.db, schema)
      .query('messages')
      .withIndex('from_to', (q) => q.eq('from', args.u1).eq('to', args.u2));

    // Stream of messages u2 → u1
    const messages2 = stream(ctx.db, schema)
      .query('messages')
      .withIndex('from_to', (q) => q.eq('from', args.u2).eq('to', args.u1));

    // Merge both streams, ordered by creation time
    const allMessages = mergedStream([messages1, messages2], ['_creationTime']);

    // Filter out archived messages
    const activeMessages = allMessages.filterWith(async (m) => !m.archived);

    return await activeMessages.paginate(args.paginationOpts);
  },
});
```

### 3. FlatMap (Joins with Pagination)

Join tables and paginate through the results:

```typescript
export const messagesFromFriends = createAuthPaginatedQuery()({
  handler: async (ctx, args) => {
    // Get friends for current user
    const friends = stream(ctx.db, schema)
      .query('friends')
      .withIndex('userId', (q) => q.eq('userId', ctx.userId));

    // For each friend, get their messages to the user
    const messages = friends.flatMap(
      (friend) =>
        stream(ctx.db, schema)
          .query('messages')
          .withIndex('from_to', (q) =>
            q.eq('from', friend.friendId).eq('to', ctx.userId)
          )
          // Include friend info with each message
          .map((message) => ({
            ...message,
            fromBestFriend: friend.isBest,
            friendshipStarted: friend._creationTime,
          })),
      ['from', 'to'] // Index fields of inner stream
    );

    return await messages.paginate(args.paginationOpts);
  },
});
```

### 4. Distinct Values

Get unique values efficiently:

```typescript
export const messageRecipients = createAuthPaginatedQuery()({
  handler: async (ctx, args) => {
    // Get all unique recipients of messages from current user
    const recipients = await stream(ctx.db, schema)
      .query('messages')
      .withIndex('from_to', (q) => q.eq('from', ctx.userId))
      .distinct(['to']) // Get first message to each unique recipient
      .map(async (message) => {
        const user = await ctx.table('user').get(message.to);
        return user!;
      })
      .paginate(args.paginationOpts);

    return recipients;
  },
});
```

### 5. Index Skip Scan

Query with partial index matches:

```typescript
export const highPriorityRecentMessages = createPublicPaginatedQuery()({
  args: { minPriority: z.number() },
  handler: async (ctx, args) => {
    // Find distinct priorities > minPriority
    const priorities = await stream(ctx.db, schema)
      .query('messages')
      .withIndex('priority', (q) => q.gt('priority', args.minPriority))
      .order('desc')
      .distinct(['priority'])
      .map((m) => m.priority)
      .collect();

    // For each priority, get recent messages
    const messages = mergedStream(
      priorities.map((priority) =>
        stream(ctx.db, schema)
          .query('messages')
          .withIndex('priority', (q) =>
            q
              .eq('priority', priority)
              .gt('_creationTime', Date.now() - 24 * 60 * 60 * 1000)
          )
          .order('desc')
      ),
      ['_creationTime'] // Merge by creation time
    );

    return await messages.paginate(args.paginationOpts);
  },
});
```

## Advanced Patterns

### Complex Filtering + Joins + Distinct

Combine multiple stream operations:

```typescript
export const uniqueActiveAuthors = createPublicPaginatedQuery()({
  args: {
    category: z.string(),
    minPosts: z.number(),
  },
  handler: async (ctx, args) => {
    // Get posts in category
    const posts = stream(ctx.db, schema)
      .query('posts')
      .withIndex('category', (q) => q.eq('category', args.category))
      // Filter by post criteria
      .filterWith(async (post) => {
        return post.published && post.views > 100;
      })
      // Get distinct authors
      .distinct(['authorId'])
      // Map to author details
      .map(async (post) => {
        const author = await ctx.table('user').get(post.authorId);
        if (!author) return null;

        // Count author's posts - use ctx.table() inside stream operations
        const postCount = await ctx
          .table('posts', 'authorId', (q) => q.eq('authorId', post.authorId))
          .filter((q) => q.eq(q.field('published'), true))
          .take(args.minPosts + 1);

        return postCount.length > args.minPosts
          ? { ...author, postCount: postCount.length }
          : null;
      })
      // Filter out nulls
      .filterWith(async (author) => author !== null);

    return await posts.paginate(args.paginationOpts);
  },
});
```

### Merge Multiple Filtered Streams

Union complex filtered queries:

```typescript
export const unifiedSearch = createPublicPaginatedQuery()({
  args: {
    query: z.string(),
    includeArchived: z.boolean().optional(),
  },
  handler: async (ctx, args) => {
    // Search in posts
    const posts = stream(ctx.db, schema)
      .query('posts')
      .withSearchIndex('search_content', (q) => q.search('content', args.query))
      .map((post) => ({
        type: 'post' as const,
        ...post,
      }));

    // Search in comments
    const comments = stream(ctx.db, schema)
      .query('comments')
      .withSearchIndex('search_text', (q) => q.search('text', args.query))
      .map((comment) => ({
        type: 'comment' as const,
        ...comment,
      }));

    // Search in profiles
    const profiles = stream(ctx.db, schema)
      .query('profiles')
      .withSearchIndex('search_bio', (q) => q.search('bio', args.query))
      .map((profile) => ({
        type: 'profile' as const,
        ...profile,
      }));

    // Merge all results by relevance/creation time
    const allResults = mergedStream(
      [posts, comments, profiles],
      ['_creationTime']
    );

    // Filter based on archived status
    const filtered = args.includeArchived
      ? allResults
      : allResults.filterWith(async (item) => {
          return !('archived' in item) || !item.archived;
        });

    return await filtered.paginate(args.paginationOpts);
  },
});
```

## Performance Considerations

### Stream Performance

1. **Document Scanning**: `filterWith` scans documents until page is full
   - Set reasonable `maximumRowsRead` in paginationOpts
   - Use indexes to reduce initial set

2. **Pagination Cursors**: More complex than regular queries
   - Include indexed fields (even from filtered docs)
   - Only work with same stream construction
   - Use `endCursor` for reactive pagination

3. **Memory Usage**: Streams are lazy
   - Documents fetched on-demand
   - Minimal memory overhead
   - Good for large datasets

### When to Use Streams vs Regular Queries

**Use Regular Queries When:**

- Simple field comparisons (eq, neq, gt, lt)
- Built-in `.filter()` is sufficient

**Use Filter Helper When:**

- Complex filters WITHOUT pagination
- Need array/string operations
- Using `.take()`, `.first()`, `.collect()`

**Use Streams When:**

- Need consistent page sizes with filters
- Combining multiple queries (UNION)
- Complex joins with pagination
- Need distinct values
- Building SQL-like patterns

## Best Practices

### 1. Always Import Schema

```typescript
import schema from './schema';

// Required for type safety
// NOTE: Stream initialization requires ctx.db
const streamQuery = stream(ctx.db, schema);
// But use ctx.table() inside stream operations!
```

### 2. Order Consistency

Ensure streams are ordered correctly for merging:

```typescript
// Both streams must be ordered by same fields
const stream1 = stream(ctx.db, schema).query('messages').withIndex('time'); // Ordered by _creationTime

const stream2 = stream(ctx.db, schema)
  .query('messages')
  .withIndex('user_time', (q) => q.eq('userId', userId));
// Still ordered by _creationTime after userId

// Can merge by _creationTime
const merged = mergedStream([stream1, stream2], ['_creationTime']);
```

### 3. Handle Nulls in Map

```typescript
const enriched = stream(ctx.db, schema)
  .query('posts')
  .map(async (post) => {
    // Use ctx.table() for lookups inside streams
    const author = await ctx.table('user').get(post.authorId);
    // Handle missing documents
    return author ? { ...post, author } : null;
  })
  .filterWith(async (post) => post !== null);
```

### 4. Limit Scanning

```typescript
// Prevent runaway queries
const results = await stream(ctx.db, schema)
  .query('posts')
  .filterWith(async (post) => expensiveCheck(post))
  .paginate({
    ...args.paginationOpts,
    maximumRowsRead: 1000, // Fail if scanning too many
  });
```

## Migration Guide

### From Filter Helper to Streams

```typescript
// ❌ OLD: Filter helper with pagination (variable page sizes)
const filtered = filter(ctx.table('characters'), (char) =>
  char.categories?.includes(args.category)
);
return await filtered.paginate(opts); // BAD: Variable page sizes!

// ✅ NEW: Stream with consistent page sizes
return await stream(ctx.db, schema)
  .query('characters')
  .filterWith(async (char) => char.categories?.includes(args.category))
  .paginate(opts);
```

### From Multiple Queries to Merged Stream

```typescript
// ❌ OLD: Fetch all and merge manually
const sent = await ctx.table('messages', 'from_to', (q) =>
  q.eq('from', u1).eq('to', u2)
);
const received = await ctx.table('messages', 'from_to', (q) =>
  q.eq('from', u2).eq('to', u1)
);
const all = [...sent, ...received].sort(
  (a, b) => b._creationTime - a._creationTime
);

// ✅ NEW: Stream and paginate
const sent = stream(ctx.db, schema)
  .query('messages')
  .withIndex('from_to', (q) => q.eq('from', u1).eq('to', u2));
const received = stream(ctx.db, schema)
  .query('messages')
  .withIndex('from_to', (q) => q.eq('from', u2).eq('to', u1));
const all = mergedStream([sent, received], ['_creationTime']);
return await all.paginate(opts);
```

## Common Pitfalls

1. **Forgetting Schema Import**: Always import and pass schema
2. **Incorrect Merge Order**: Streams must be ordered by merge fields
3. **Not Handling Nulls**: Map operations can return null
4. **Infinite Scanning**: Use maximumRowsRead to prevent runaway queries
5. **Cursor Fragility**: Stream structure must be identical between requests

## Summary

Streams enable SQL-like query patterns in Convex:

- **UNION**: `mergedStream()` combines multiple queries
- **JOIN**: `flatMap()` expands items into streams
- **WHERE**: `filterWith()` with arbitrary TypeScript
- **DISTINCT**: `distinct()` for unique values
- **Consistent Pagination**: Filter before paginating

**IMPORTANT REMINDER:** Streams still require `ctx.db` for initialization (`stream(ctx.db, schema)`), but you SHOULD use `ctx.table()` for all database operations inside stream callbacks like `filterWith`, `map`, etc. The only exception is when using stream-specific query syntax that hasn't been migrated to Ents.

Use streams when you need complex queries with predictable pagination behavior.
